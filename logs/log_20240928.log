2024-09-28 23:35:21 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:35:21 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:35:21 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:35:21 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:35:21 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:35:21 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:35:21 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:35:21 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:35:21 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:35:21 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:35:21 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init llm : model='llama3.1:8b' temperature=0.0 top_p=0.9
2024-09-28 23:35:21 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='llama3.1:8b', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='llama3.1:8b' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:36:24 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:36:24 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:36:24 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:36:24 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:36:24 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:36:24 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:36:24 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:36:24 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:36:24 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:36:24 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:36:24 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init llm : model='llama3.1:8b' temperature=0.0 top_p=0.9
2024-09-28 23:36:24 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='llama3.1:8b', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='llama3.1:8b' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:36:43 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:36:43 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:36:43 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:36:43 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:36:43 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:36:43 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:36:43 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:36:43 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:36:43 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:36:43 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:36:43 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init llm : model='llama3.1:8b' temperature=0.0 top_p=0.9
2024-09-28 23:36:43 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='llama3.1:8b', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='llama3.1:8b' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:37:37 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:37:37 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:37:37 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:37:37 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:37:37 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:37:37 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:37:37 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:37:37 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:37:37 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:37:37 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:37:37 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init llm : model='llama3.1:8b' temperature=0.0 top_p=0.9
2024-09-28 23:37:37 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='llama3.1:8b', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='llama3.1:8b' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:38:03 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:38:03 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:38:03 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:38:03 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:38:03 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:38:03 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:38:04 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:38:04 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:38:04 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:38:04 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:38:04 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init llm : model='llama3.1:8b' temperature=0.0 top_p=0.9
2024-09-28 23:38:04 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='llama3.1:8b', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='llama3.1:8b' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:39:11 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:39:11 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:39:11 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:39:11 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:39:11 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:39:11 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:39:11 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:39:11 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:39:11 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:39:11 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:39:11 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init llm : model='llama3.1:8b' temperature=0.0 top_p=0.9
2024-09-28 23:39:11 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='llama3.1:8b', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='llama3.1:8b' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:39:15 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:39:15 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:39:15 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:39:15 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:39:15 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:39:15 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:39:16 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:39:16 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:39:16 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:39:16 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:39:16 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='qwen2.5:latest', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='qwen2.5:latest' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:39:44 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:39:44 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:39:44 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:39:44 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:39:44 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:39:44 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:39:44 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:39:44 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:39:44 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:39:44 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:39:44 - kfm_framework.imp.kfm_chain.Chain1 - DEBUG - Chain1 is initialization
2024-09-28 23:39:44 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='qwen2.5:latest', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='qwen2.5:latest' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:39:59 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:39:59 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:39:59 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:39:59 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:39:59 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:39:59 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:39:59 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:39:59 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:39:59 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:39:59 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:39:59 - kfm_framework.imp.kfm_chain.Chain1 - DEBUG - Chain1 is initialization
2024-09-28 23:39:59 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='qwen2.5:latest', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='qwen2.5:latest' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:43:54 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:43:54 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:43:54 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:43:54 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:43:54 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:43:54 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:43:54 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:43:54 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:43:54 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:43:54 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:43:54 - kfm_framework.imp.kfm_chain.Chain1 - DEBUG - Chain1 is initialization
2024-09-28 23:43:54 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='qwen2.5:latest', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='qwen2.5:latest' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:44:11 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:44:11 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:44:11 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:44:11 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:44:11 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:44:11 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:44:11 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:44:11 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:44:11 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:44:11 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:44:11 - kfm_framework.imp.kfm_chain.Chain1 - DEBUG - Chain1 is initialization
2024-09-28 23:44:11 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='qwen2.5:latest', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='qwen2.5:latest' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:44:36 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:44:36 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:44:36 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:44:36 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:44:36 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:44:36 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:44:36 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:44:36 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:44:36 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:44:36 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:44:42 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:44:42 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:44:42 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:44:42 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:44:42 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:44:42 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:44:42 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:44:42 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:44:42 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:44:42 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:45:31 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:45:31 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:45:31 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:45:31 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:45:31 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:45:31 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:45:31 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:45:31 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:45:31 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:45:31 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:46:50 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:46:50 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:46:50 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:46:50 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:46:50 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:46:50 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:46:50 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:46:50 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:46:50 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:46:50 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:47:20 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:47:20 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:47:20 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:47:20 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:47:20 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:47:20 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:47:20 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:47:20 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:47:20 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:47:20 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:47:35 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:47:35 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:47:35 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:47:35 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:47:35 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:47:35 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:47:35 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:47:35 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:47:35 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:47:35 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:48:06 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:48:06 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:48:06 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:48:06 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:48:06 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:48:06 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:48:06 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:48:06 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:48:06 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:48:06 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:48:30 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:48:30 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:48:30 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:48:30 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:48:30 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:48:30 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:48:30 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:48:30 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:48:30 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:48:30 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:48:40 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:48:40 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:48:40 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:48:40 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:48:40 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:48:40 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:48:40 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:48:40 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:48:40 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:48:40 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:48:40 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - Chain3 is initialization
2024-09-28 23:48:40 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='qwen2.5:latest', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='qwen2.5:latest' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:48:40 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - get_session_history db_path : sqlite:////Users/linrui/PycharmProjects/everyone_llm_framework/chain_memory_data/chain3_memory.db
2024-09-28 23:48:59 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:48:59 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:48:59 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:48:59 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:48:59 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:48:59 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:48:59 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:48:59 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:48:59 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:48:59 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:48:59 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - Chain3 is initialization
2024-09-28 23:48:59 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='qwen2.5:latest', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='qwen2.5:latest' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:48:59 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - get_session_history db_path : sqlite:////Users/linrui/PycharmProjects/everyone_llm_framework/chain_memory_data/chain3_memory.db
2024-09-28 23:49:24 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:49:24 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:49:24 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:49:24 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:49:24 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:49:41 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:49:41 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:49:41 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:49:41 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:49:41 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:49:41 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:49:41 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:49:41 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:49:41 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:49:41 - kfm_framework.imp.kfm_model.KfmModel1 - INFO - KfmModel1 init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:49:41 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - Chain3 is initialization
2024-09-28 23:49:41 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='qwen2.5:latest', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='qwen2.5:latest' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:49:42 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - get_session_history db_path : sqlite:////Users/linrui/PycharmProjects/everyone_llm_framework/chain_memory_data/chain3_memory.db
2024-09-28 23:49:47 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:49:47 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:49:47 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:49:47 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:49:47 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:49:47 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:49:47 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:49:47 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:49:47 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:49:47 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:49:47 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init llm : model='llama3.1:8b' temperature=0.0 top_p=0.9
2024-09-28 23:49:47 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - Chain3 is initialization
2024-09-28 23:49:47 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='llama3.1:8b', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='llama3.1:8b' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:49:47 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - get_session_history db_path : sqlite:////Users/linrui/PycharmProjects/everyone_llm_framework/chain_memory_data/chain3_memory.db
2024-09-28 23:58:21 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:58:21 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:58:21 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:58:21 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:58:21 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:58:21 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:58:21 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:58:21 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:58:21 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:58:21 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:58:21 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init llm : model='llama3.1:8b' temperature=0.0 top_p=0.9
2024-09-28 23:58:21 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - Chain3 is initialization
2024-09-28 23:58:21 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='llama3.1:8b', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='llama3.1:8b' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:58:21 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - get_session_history db_path : sqlite:////Users/linrui/PycharmProjects/everyone_llm_framework/chain_memory_data/chain3_memory.db
2024-09-28 23:58:27 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:58:27 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:58:27 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:58:27 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:58:27 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:58:27 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:58:27 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:58:27 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:58:27 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:58:27 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:58:27 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init llm : model='llama3.1:8b' temperature=0.0 top_p=0.9
2024-09-28 23:58:27 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - Chain3 is initialization
2024-09-28 23:58:27 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='llama3.1:8b', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='llama3.1:8b' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:58:27 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - get_session_history db_path : sqlite:////Users/linrui/PycharmProjects/everyone_llm_framework/chain_memory_data/chain3_memory.db
2024-09-28 23:58:58 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - python version: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 12:57:28) [Clang 14.0.6 ]
2024-09-28 23:58:58 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - LangChain version: 0.2.14,langchain_core version:0.2.33 Chromadb version: 0.5.5
2024-09-28 23:58:58 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - langchain_community version: 0.2.12,	 Chromadb version: 0.5.5
2024-09-28 23:58:58 - kfm_core.kfm_chatllama.KfmChatLlama - INFO - llm is model='qwen2.5:latest' temperature=0.0 top_p=0.9 ,kfm_stream_llm is model='qwen2' temperature=0.1 top_p=0.9  embedding :base_url='http://localhost:11434' model='nomic-embed-text:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None
2024-09-28 23:58:58 - kfm_core.kfm_chatllama.KfmChatLlama - DEBUG - KfmChatLlama LLM is  initialization completed ✅  
2024-09-28 23:58:58 - kfm_framework.imp.kfm_model.KfmModel2 - DEBUG - KfmModel2 initialization
2024-09-28 23:58:58 - kfm_framework.Kfm_Chatbot - DEBUG - kfm_chatbot initialization
2024-09-28 23:58:58 - kfm_framework.Kfm_Chatbot - DEBUG - Kfm_Chatbot LLM is initialization
2024-09-28 23:58:58 - kfm_framework.Kfm_Chatbot - DEBUG - ====================== LLM is initialization ======================
2024-09-28 23:58:58 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init params : [{'p1': 0, 'p2': 0, 'p3': 0}, {'top': 1, 'max_token': 9000}]
2024-09-28 23:58:58 - kfm_framework.imp.kfm_model.KfmModel2 - INFO - KfmModel2 B init llm : model='llama3.1:8b' temperature=0.0 top_p=0.9
2024-09-28 23:58:58 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - Chain3 is initialization
2024-09-28 23:58:58 - kfm_framework.Kfm_Chatbot - DEBUG - self.chain_dict:
 {'vector': 'Vectorized by Vector2: hi', 'kfm_embedding': 'Embedded by Embedding2: Vectorized by Vector2: hi', 'model': ChatOllama(model='llama3.1:8b', temperature=0.0, top_p=0.9), 'template': "Template2 applied: model='llama3.1:8b' temperature=0.0 top_p=0.9", 'input': 'hi', 'user_id': 'linrui', 'session_id': '123'}
2024-09-28 23:58:58 - kfm_framework.imp.kfm_chain.Chain3 - DEBUG - get_session_history db_path : sqlite:////Users/linrui/PycharmProjects/everyone_llm_framework/chain_memory_data/chain3_memory.db
